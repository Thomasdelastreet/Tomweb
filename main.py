import requests
import sqlite3
import time
from bs4 import BeautifulSoup

# Configuration du site √† scraper
URL = "https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal"  # Remplace par l'URL cible
INTERVALLE = 60  # Temps d'attente entre deux scans (en secondes)

# Initialisation de la base SQLite
conn = sqlite3.connect("articles.db")
cursor = conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS articles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    titre TEXT,
    sous_titre TEXT,
    lien TEXT UNIQUE
)
""")
conn.commit()

def recuperer_articles():
    """R√©cup√®re les titres, sous-titres et liens des articles"""
    try:
        response = requests.get(URL, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()  # V√©rifie si la requ√™te a r√©ussi
    except requests.RequestException as e:
        print(f"Erreur de connexion : {e}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    articles = []

    # Adaptation selon la structure du site (exemple g√©n√©rique)
    for article in soup.select("article"):  # Modifier le s√©lecteur selon le site
        titre = article.select_one("h2").text.strip() if article.select_one("h2") else "Sans titre"
        sous_titre = article.select_one("p").text.strip() if article.select_one("p") else "Sans sous-titre"
        lien = article.select_one("a")["href"] if article.select_one("a") else None
        
        if lien and not lien.startswith("http"):
            lien = URL + lien  # Conversion des liens relatifs en absolus
        
        if lien:
            articles.append((titre, sous_titre, lien))
    
    return articles

def enregistrer_articles(articles):
    """Enregistre les articles dans la base de donn√©es en √©vitant les doublons"""
    for titre, sous_titre, lien in articles:
        try:
            cursor.execute("INSERT INTO articles (titre, sous_titre, lien) VALUES (?, ?, ?)", (titre, sous_titre, lien))
            conn.commit()
            print(f"‚úÖ Nouveau : {titre}")
        except sqlite3.IntegrityError:
            print(f"‚ö†Ô∏è D√©j√† enregistr√© : {titre}")

if __name__ == "__main__":
    while True:
        print("\nüîÑ Scraping en cours...")
        articles = recuperer_articles()
        if articles:
            enregistrer_articles(articles)
        else:
            print("‚ö†Ô∏è Aucune donn√©e r√©cup√©r√©e.")
        
        print(f"‚è≥ Attente de {INTERVALLE} secondes...")
        time.sleep(INTERVALLE)
